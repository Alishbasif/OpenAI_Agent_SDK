# ğŸ›¡ï¸ Input Guardrails in OpenAI Agent SDK
## ğŸ“˜ What are Input Guardrails?

Input Guardrails are rules or checks applied to the userâ€™s input before it reaches the model or agent.
They are used to filter, validate, or block unsafe/unwanted inputs.

## â“ Why do we need Input Guardrails?

- âœ… Prevent harmful or malicious inputs.

- âœ… Ensure inputs are in the correct format.

- âœ… Enforce business logic or constraints.

- âœ… Protect your Agent from unsafe queries.

## ğŸš€ Input Guardrails in OpenAI SDK

In the Agent SDK, Input Guardrails:

- Run before the Agent processes input.

- Can block execution if a rule is triggered.

- Can raise an InputGuardrailTripwireTriggered event.

- Work with multiple guardrails (all are checked).
## âš¡ How this works?

- Guardrail function checks input before model sees it.

- If condition matches â†’ InputGuardrailTripwireTriggered is raised.

- Execution stops, and agent doesnâ€™t process unsafe input.

- If safe â†’ normal flow continues.

## â­ Next Steps

- Add multiple guardrails for format + safety.

- Log triggered guardrails for monitoring.

- Combine with output guardrails for full safety pipeline.

